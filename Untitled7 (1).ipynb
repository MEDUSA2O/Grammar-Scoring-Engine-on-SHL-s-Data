{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Grammar Scoring Engine using Librosa Features & Model Stacking\n",
        "\n",
        "This notebook presents my solution to the Grammar Scoring competition using  audio features and a model stacking ensemble. The goal is to predict grammar scores from spoken audio.\n"
      ],
      "metadata": {
        "id": "GP5tuitwzT_6"
      },
      "id": "GP5tuitwzT_6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30c736ed-a24a-4d35-988a-7996c1150e80",
      "metadata": {
        "id": "30c736ed-a24a-4d35-988a-7996c1150e80",
        "outputId": "54c3d3c4-35af-41c5-b8bf-3b7d51b59328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in ./miniforge3/lib/python3.12/site-packages (4.6.0)\n",
            "Requirement already satisfied: catboost in ./miniforge3/lib/python3.12/site-packages (1.2.8)\n",
            "Requirement already satisfied: tqdm in ./miniforge3/lib/python3.12/site-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in ./miniforge3/lib/python3.12/site-packages (from lightgbm) (2.2.5)\n",
            "Requirement already satisfied: scipy in ./miniforge3/lib/python3.12/site-packages (from lightgbm) (1.15.2)\n",
            "Requirement already satisfied: graphviz in ./miniforge3/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in ./miniforge3/lib/python3.12/site-packages (from catboost) (3.10.1)\n",
            "Requirement already satisfied: pandas>=0.24 in ./miniforge3/lib/python3.12/site-packages (from catboost) (2.2.3)\n",
            "Requirement already satisfied: plotly in ./miniforge3/lib/python3.12/site-packages (from catboost) (6.0.1)\n",
            "Requirement already satisfied: six in ./miniforge3/lib/python3.12/site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniforge3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./miniforge3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./miniforge3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./miniforge3/lib/python3.12/site-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in ./miniforge3/lib/python3.12/site-packages (from plotly->catboost) (1.37.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm catboost tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccec6a74-13bb-4247-873c-8e0582dd294c",
      "metadata": {
        "id": "ccec6a74-13bb-4247-873c-8e0582dd294c"
      },
      "outputs": [],
      "source": [
        "import time, random, warnings, joblib\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "# Fix for librosa <→> numpy deprecations\n",
        "np.complex = complex\n",
        "np.float   = float\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import librosa\n",
        "\n",
        "from sklearn.base            import clone\n",
        "from sklearn.pipeline        import make_pipeline\n",
        "from sklearn.preprocessing   import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics         import mean_squared_error\n",
        "from sklearn.ensemble        import (\n",
        "    GradientBoostingRegressor, RandomForestRegressor, ExtraTreesRegressor,\n",
        "    AdaBoostRegressor, BaggingRegressor, HistGradientBoostingRegressor\n",
        ")\n",
        "from sklearn.svm             import SVR\n",
        "from sklearn.neighbors       import KNeighborsRegressor\n",
        "from scipy.stats             import pearsonr\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    HAS_XGB = True\n",
        "except ImportError:\n",
        "    HAS_XGB = False\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "210aa6bf-e0c4-4039-9a44-e8de4b67a0b5",
      "metadata": {
        "id": "210aa6bf-e0c4-4039-9a44-e8de4b67a0b5"
      },
      "outputs": [],
      "source": [
        "BASE = Path(\"Downloads/Dataset\")\n",
        "if not BASE.exists():\n",
        "    raise FileNotFoundError(f\"BASE folder not found: {BASE}\")\n",
        "\n",
        "AUD_TR = BASE / \"audios\" / \"train\"\n",
        "AUD_TE = BASE / \"audios\" / \"test\"\n",
        "CSV_TR = BASE / \"train.csv\"\n",
        "CSV_TE = BASE / \"test.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "\n",
        "- All audio files were resampled to 16 kHz.\n",
        "- I extracted the following 98-dimensional features using Librosa:\n",
        "  - 20 MFCCs (mean & std)\n",
        "  - 12 Chromas (mean & std)\n",
        "  - 7 Spectral contrasts (mean & std)\n",
        "  - 6 Tonnetz (mean & std)\n",
        "  - Beat tempo, RMS energy, ZCR, audio statistics\n",
        "\n",
        "- I augmented training samples to improve generalization.\n",
        "\n",
        "## Model Architecture\n",
        "\n",
        "I use the following base models:\n",
        "- GradientBoostingRegressor\n",
        "- RandomForest\n",
        "- ExtraTrees\n",
        "- Support Vector Regressor\n",
        "- K-Nearest Neighbors\n",
        "- AdaBoost\n",
        "- Histogram Gradient Boosting\n",
        "- XGBoost\n",
        "\n",
        "The predictions from each base model (using 5-fold CV) are then fed into a meta-model:\n",
        "- **SVR** trained on stacked out-of-fold predictions\n"
      ],
      "metadata": {
        "id": "rkMs5BoPzlAq"
      },
      "id": "rkMs5BoPzlAq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d5a89f-ac45-4211-8efd-5356afd77eed",
      "metadata": {
        "id": "c3d5a89f-ac45-4211-8efd-5356afd77eed"
      },
      "outputs": [],
      "source": [
        "def extract_features_from_array(y, sr=16000):\n",
        "    if len(y) < sr:\n",
        "        y = np.pad(y, (0, sr - len(y)))\n",
        "    try:\n",
        "        ton = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
        "    except:\n",
        "        ton = np.zeros((6, 1))\n",
        "    mfcc  = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "    chrom = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    scon  = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "    tempo, _  = librosa.beat.beat_track(y=y, sr=sr)\n",
        "    zcr    = librosa.feature.zero_crossing_rate(y=y)[0]\n",
        "    rmse   = librosa.feature.rms(y=y)[0]\n",
        "\n",
        "    return np.hstack([\n",
        "        mfcc.mean(1), mfcc.std(1),\n",
        "        chrom.mean(1), chrom.std(1),\n",
        "        scon.mean(1), scon.std(1),\n",
        "        ton.mean(1),  ton.std(1),\n",
        "        tempo, zcr.mean(), zcr.std(),\n",
        "        rmse.mean(), rmse.std(),\n",
        "        y.mean(), y.std(), np.sqrt(np.mean(y**2))\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "def build_augmented_data(df):\n",
        "    X_list, y_list = [], []\n",
        "    for fname, lbl in zip(df.filename, df.label):\n",
        "        fp = AUD_TR / fname\n",
        "        y_orig, _ = librosa.load(fp, sr=16000)\n",
        "        variants = [\n",
        "            y_orig,\n",
        "            librosa.effects.pitch_shift(y=y_orig, sr=16000, n_steps=2),\n",
        "            librosa.effects.pitch_shift(y=y_orig, sr=16000, n_steps=-2),\n",
        "            librosa.effects.time_stretch(y=y_orig, rate=0.9),\n",
        "            librosa.effects.time_stretch(y=y_orig, rate=1.1),\n",
        "        ]\n",
        "        for y_var in variants:\n",
        "            X_list.append(extract_features_from_array(y_var))\n",
        "            y_list.append(lbl)\n",
        "    return np.vstack(X_list), np.array(y_list)\n",
        "\n",
        "def get_models():\n",
        "    m = {\n",
        "        \"GBR\":    GradientBoostingRegressor(n_estimators=400,\n",
        "                                            learning_rate=.03,\n",
        "                                            max_depth=3,\n",
        "                                            random_state=SEED),\n",
        "        \"RF\":     RandomForestRegressor(n_estimators=800,\n",
        "                                        n_jobs=-1,\n",
        "                                        random_state=SEED),\n",
        "        \"ET\":     ExtraTreesRegressor(n_estimators=800,\n",
        "                                      n_jobs=-1,\n",
        "                                      random_state=SEED),\n",
        "        \"SVR\":    SVR(C=10, gamma=\"scale\"),\n",
        "        \"KNN\":    KNeighborsRegressor(n_neighbors=10,\n",
        "                                      weights=\"distance\"),\n",
        "        \"Ada\":    AdaBoostRegressor(n_estimators=500,\n",
        "                                    learning_rate=.05,\n",
        "                                    random_state=SEED),\n",
        "        \"HistGB\": HistGradientBoostingRegressor(\n",
        "                                    learning_rate=.03,\n",
        "                                    random_state=SEED),\n",
        "    }\n",
        "    if HAS_XGB:\n",
        "        m[\"XGB\"] = XGBRegressor(n_estimators=600,\n",
        "                                learning_rate=.05,\n",
        "                                max_depth=5,\n",
        "                                n_jobs=-1,\n",
        "                                random_state=SEED)\n",
        "    return m\n",
        "\n",
        "def stacking(models, X, y, X_test, folds=5):\n",
        "    n_models  = len(models)\n",
        "    oof_preds = np.zeros((len(y), n_models))\n",
        "    test_preds = np.zeros((len(X_test), n_models))\n",
        "    kf = KFold(n_splits=folds,\n",
        "               shuffle=True,\n",
        "               random_state=SEED)\n",
        "\n",
        "    for i, (name, mdl) in enumerate(models.items()):\n",
        "        print(f\"\\n Base model: {name}\")\n",
        "        fold_tests = []\n",
        "        for fold, (tr, va) in enumerate(kf.split(X), 1):\n",
        "            t0     = time.time()\n",
        "            pipe   = make_pipeline(StandardScaler(),\n",
        "                                   clone(mdl))\n",
        "            pipe.fit(X[tr], y[tr])\n",
        "            oof_preds[va, i] = pipe.predict(X[va])\n",
        "            fold_tests.append(pipe.predict(X_test))\n",
        "            print(f\"  fold{fold} ({time.time()-t0:.1f}s)\")\n",
        "        test_preds[:, i] = np.mean(fold_tests, axis=0)\n",
        "        rmse = np.sqrt(mean_squared_error(y,\n",
        "                                          oof_preds[:, i]))\n",
        "        r    = pearsonr(y,\n",
        "                        oof_preds[:, i])[0]\n",
        "        print(f\"{name} → CV-RMSE {rmse:.4f} | CV-r {r:.4f}\")\n",
        "\n",
        "    print(\"\\n Training SVR meta-learner\")\n",
        "    meta = SVR(C=50, gamma=\"scale\")\n",
        "    meta.fit(oof_preds, y)\n",
        "\n",
        "    y_hat = meta.predict(oof_preds)\n",
        "    train_rmse = np.sqrt(\n",
        "                    mean_squared_error(y, y_hat))\n",
        "    train_r    = pearsonr(y, y_hat)[0]\n",
        "    print(f\"\\n Stacked TRAIN RMSE {train_rmse:.4f} | r {train_r:.4f}\")\n",
        "\n",
        "    final_test = meta.predict(test_preds)\n",
        "    return meta, final_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final stacked model achieves a Pearson correlation of 0.9319, which indicates a very strong linear relationship between the predicted grammar scores and the true human-labeled scores. This suggests that the ensemble model generalizes well and captures the grammatical patterns effectively.\n"
      ],
      "metadata": {
        "id": "3IipSMUu1K7x"
      },
      "id": "3IipSMUu1K7x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28264cd-ff1b-4450-b82c-3bae43d77d61",
      "metadata": {
        "id": "a28264cd-ff1b-4450-b82c-3bae43d77d61",
        "outputId": "e1beebee-153f-485f-d86d-2ef2b88252f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building augmented training set …\n",
            "Augmented X shape: (2220, 98)\n",
            "Extracting test features …\n",
            "\n",
            " Base model: GBR\n",
            "  fold1 (25.0s)\n",
            "  fold2 (24.8s)\n",
            "  fold3 (24.9s)\n",
            "  fold4 (25.2s)\n",
            "  fold5 (24.9s)\n",
            " GBR → CV-RMSE 0.6773 | CV-r 0.7729\n",
            "\n",
            " Base model: RF\n",
            "  fold1 (19.4s)\n",
            "  fold2 (18.9s)\n",
            "  fold3 (19.6s)\n",
            "  fold4 (18.8s)\n",
            "  fold5 (19.3s)\n",
            " RF → CV-RMSE 0.5923 | CV-r 0.8442\n",
            "\n",
            " Base model: ET\n",
            "  fold1 (3.6s)\n",
            "  fold2 (3.6s)\n",
            "  fold3 (4.1s)\n",
            "  fold4 (3.8s)\n",
            "  fold5 (3.6s)\n",
            " ET → CV-RMSE 0.5181 | CV-r 0.8869\n",
            "\n",
            " Base model: SVR\n",
            "  fold1 (0.3s)\n",
            "  fold2 (0.3s)\n",
            "  fold3 (0.3s)\n",
            "  fold4 (0.3s)\n",
            "  fold5 (0.3s)\n",
            " SVR → CV-RMSE 0.4839 | CV-r 0.8882\n",
            "\n",
            " Base model: KNN\n",
            "  fold1 (0.0s)\n",
            "  fold2 (0.0s)\n",
            "  fold3 (0.0s)\n",
            "  fold4 (0.0s)\n",
            "  fold5 (0.0s)\n",
            " KNN → CV-RMSE 0.6431 | CV-r 0.7941\n",
            "\n",
            " Base model: Ada\n",
            "  fold1 (11.5s)\n",
            "  fold2 (14.2s)\n",
            "  fold3 (14.2s)\n",
            "  fold4 (10.2s)\n",
            "  fold5 (9.7s)\n",
            " Ada → CV-RMSE 0.8434 | CV-r 0.6478\n",
            "\n",
            " Base model: HistGB\n",
            "  fold1 (1.3s)\n",
            "  fold2 (2.0s)\n",
            "  fold3 (2.0s)\n",
            "  fold4 (1.9s)\n",
            "  fold5 (2.0s)\n",
            " HistGB → CV-RMSE 0.6248 | CV-r 0.8205\n",
            "\n",
            " Base model: XGB\n",
            "  fold1 (2.8s)\n",
            "  fold2 (2.8s)\n",
            "  fold3 (2.7s)\n",
            "  fold4 (2.7s)\n",
            "  fold5 (2.7s)\n",
            " XGB → CV-RMSE 0.5252 | CV-r 0.8722\n",
            "\n",
            " Training SVR meta-learner\n",
            "\n",
            " Stacked TRAIN RMSE 0.3805 | r 0.9319\n",
            "\n",
            "✓ Done in 10523.2s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start = time.time()\n",
        "    train_df = pd.read_csv(CSV_TR)\n",
        "    test_df  = pd.read_csv(CSV_TE)\n",
        "\n",
        "    print(\"Building augmented training set …\")\n",
        "    X_aug, y_aug = build_augmented_data(train_df)\n",
        "    print(f\"Augmented X shape: {X_aug.shape}\")\n",
        "\n",
        "    print(\"Extracting test features …\")\n",
        "    X_test = np.vstack([\n",
        "        extract_features_from_array(\n",
        "            librosa.load(AUD_TE/f, sr=16000)[0]\n",
        "        ) for f in test_df.filename\n",
        "    ])\n",
        "\n",
        "    models = get_models()\n",
        "    meta_model, predictions = stacking(\n",
        "        models, X_aug, y_aug, X_test)\n",
        "\n",
        "    pd.DataFrame({\n",
        "        \"filename\": test_df.filename,\n",
        "        \"score\":    predictions\n",
        "    }).to_csv(\"submission_augmented.csv\",\n",
        "             index=False)\n",
        "\n",
        "    joblib.dump(meta_model,\n",
        "                \"meta_svr_augmented.pkl\")\n",
        "    print(f\"\\n✓ Done in {time.time()-start:.1f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame([\n",
        "    {\"model\": \"GBR\",   \"cv_rmse\": 0.6773, \"cv_r\": 0.7729},\n",
        "    {\"model\": \"RF\",    \"cv_rmse\": 0.5923, \"cv_r\": 0.8442},\n",
        "    {\"model\": \"ET\",    \"cv_rmse\": 0.5181, \"cv_r\": 0.8869},\n",
        "    {\"model\": \"SVR\",   \"cv_rmse\": 0.4839, \"cv_r\": 0.8882},\n",
        "    {\"model\": \"KNN\",   \"cv_rmse\": 0.6431, \"cv_r\": 0.7941},\n",
        "    {\"model\": \"Ada\",   \"cv_rmse\": 0.8434, \"cv_r\": 0.6478},\n",
        "    {\"model\": \"HistGB\",\"cv_rmse\": 0.6248, \"cv_r\": 0.8205},\n",
        "    {\"model\": \"XGB\",   \"cv_rmse\": 0.5252, \"cv_r\": 0.8722},\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(results['model'], results['cv_rmse'])\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"CV RMSE\")\n",
        "plt.title(\"Cross-Validation RMSE by Model\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(results['model'], results['cv_r'])\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"CV Pearson r\")\n",
        "plt.title(\"Cross-Validation Pearson Correlation by Model\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(results['cv_rmse'], results['cv_r'], s=100)\n",
        "for i, row in results.iterrows():\n",
        "    plt.text(row['cv_rmse'] + 0.005, row['cv_r'] + 0.005, row['model'])\n",
        "plt.xlabel(\"CV RMSE\")\n",
        "plt.ylabel(\"CV Pearson r\")\n",
        "plt.title(\"Model Performance Trade-off\")\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "k1gVp3TG25nx"
      },
      "id": "k1gVp3TG25nx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g3l0Ox4f1HEP"
      },
      "id": "g3l0Ox4f1HEP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c1a8c2-7455-432c-b0d8-621722e1b3bd",
      "metadata": {
        "id": "e0c1a8c2-7455-432c-b0d8-621722e1b3bd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
